{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLarge language models are powerful neural networks trained on large amounts of text data to generate human-like language.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model=\"text-davinci-003\")\n",
    "llm(\"Explan large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.3)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data\"),\n",
    "]\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's an example of a Python script that trains a neural network on simulated data using the Keras library:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(100, 2)\n",
      "y = np.random.randint(2, size=(100, 1))\n",
      "\n",
      "# Define the neural network architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(4, input_dim=2, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=10)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f\"Loss: {loss}\")\n",
      "print(f\"Accuracy: {accuracy}\")\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using `np.random.rand()` and `np.random.randint()`. Then, we define the neural network architecture using the `Sequential` model from Keras. The model consists of two dense layers, with the first layer having 4 neurons and the second layer having 1 neuron. The activation functions used are ReLU for the first layer and sigmoid for the second layer.\n",
      "\n",
      "After defining the model, we compile it using the binary cross-entropy loss function and the Adam optimizer. Then, we train the model using the `fit()` function, specifying the number of epochs and the batch size.\n",
      "\n",
      "Finally, we evaluate the trained model using the `evaluate()` function and print the loss and accuracy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with expertise in building deep learning models.\n",
    "Explain the concept of {concept} in a few lines.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"concept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['concept'], output_parser=None, partial_variables={}, template='\\nYou are an expert data scientist with expertise in building deep learning models.\\nExplain the concept of {concept} in a few lines.\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRegularization is a technique used to reduce the overfitting of a model by adding a penalty term to the cost function. It helps to reduce the complexity of a model by penalizing large weights, which helps to reduce the variance of the model, thus improving its generalization ability. Regularization techniques such as L1 or L2 regularization can be used to reduce the complexity of a model and prevent overfitting.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed the prompt to the LLM\n",
    "completion = llm(prompt.format(concept=\"Regularization\"))\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regularization is a technique used to reduce the overfitting of a model by adding a penalty term to the cost function. It helps to reduce the complexity of a model by penalizing large weights, which helps to reduce the variance of the model, thus improving its generalization ability. Regularization techniques such as L1 or L2 regularization can be used to reduce the complexity of a model and prevent overfitting.\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Autoencoders are a type of artificial neural network used to learn data representations in an unsupervised fashion. Autoencoders are composed of an encoder and a decoder, both of which are often multilayer neural networks. The encoder compresses the input data into a compressed representation, while the decoder attempts to reconstruct the original input. Autoencoders can be used for dimensionality reduction, feature extraction, anomaly detection, and image reconstruction.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable\n",
    "print(chain.run(concept=\"Autoencoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=\"Explain the concept of {concept} like I am five years old, in 500 words or less.\",\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "Autoencoders are a type of neural network that are used for unsupervised learning. They use an input layer, one or more hidden layers, and an output layer, with the goal of learning a compressed representation of the input data. The hidden layers are typically smaller than the input and output layers, allowing the autoencoder to learn a compressed version of the input data, which can then be used for a variety of tasks such as image compression, anomaly detection, and feature extraction.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Autoencoders are a type of artificial neural network that are used for unsupervised learning. They are a type of ‘deep learning’ algorithm, which means they use multiple layers of neurons to learn patterns in data. Autoencoders take an input of data and use the layers of neurons to learn a compressed representation of that data. An autoencoder has three main components: an input layer, one or more hidden layers, and an output layer. The input layer takes in the data, the hidden layers learn patterns in the data, and the output layer produces a compressed representation of the input. \n",
      "\n",
      "The hidden layers of the autoencoder are typically smaller than the input and output layers, allowing the autoencoder to learn a compressed version of the input data. This compressed representation can then be used for a variety of tasks, such as image compression, anomaly detection, and feature extraction. Autoencoders are often used to reduce the amount of data needed to represent a given input, as they can learn to ignore unnecessary information and focus on the important features of the input. \n",
      "\n",
      "Overall, autoencoders are a powerful tool for unsupervised learning. They can be used to find patterns in data\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Autoencoders are a type of artificial neural network that are used for unsupervised learning. They are a type of ‘deep learning’ algorithm, which means they use multiple layers of neurons to learn patterns in data. Autoencoders take an input of data and use the layers of neurons to learn a compressed representation of that data. An autoencoder has three main components: an input layer, one or more hidden layers, and an output layer. The input layer takes in the data, the hidden layers learn patterns in the data, and the output layer produces a compressed representation of the input. \n",
      "\n",
      "The hidden layers of the autoencoder are typically smaller than the input and output layers, allowing the autoencoder to learn a compressed version of the input data. This compressed representation can then be used for a variety of tasks, such as image compression, anomaly detection, and feature extraction. Autoencoders are often used to reduce the amount of data needed to represent a given input, as they can learn to ignore unnecessary information and focus on the important features of the input. \n",
      "\n",
      "Overall, autoencoders are a powerful tool for unsupervised learning. They can be used to find patterns in data\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "final_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the final chain specifying only the input variable for the first chain.abs\n",
    "explanation = final_chain.run(\"Autoencoder\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explanation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Autoencoders are a type of artificial neural network that are used for unsupervised learning. They', metadata={}),\n",
       " Document(page_content='are a type of ‘deep learning’ algorithm, which means they use multiple layers of neurons to learn', metadata={}),\n",
       " Document(page_content='patterns in data. Autoencoders take an input of data and use the layers of neurons to learn a', metadata={}),\n",
       " Document(page_content='compressed representation of that data. An autoencoder has three main components: an input layer,', metadata={}),\n",
       " Document(page_content='one or more hidden layers, and an output layer. The input layer takes in the data, the hidden', metadata={}),\n",
       " Document(page_content='layers learn patterns in the data, and the output layer produces a compressed representation of the', metadata={}),\n",
       " Document(page_content='input.', metadata={}),\n",
       " Document(page_content='The hidden layers of the autoencoder are typically smaller than the input and output layers,', metadata={}),\n",
       " Document(page_content='allowing the autoencoder to learn a compressed version of the input data. This compressed', metadata={}),\n",
       " Document(page_content='representation can then be used for a variety of tasks, such as image compression, anomaly', metadata={}),\n",
       " Document(page_content='detection, and feature extraction. Autoencoders are often used to reduce the amount of data needed', metadata={}),\n",
       " Document(page_content='to represent a given input, as they can learn to ignore unnecessary information and focus on the', metadata={}),\n",
       " Document(page_content='important features of the input.', metadata={}),\n",
       " Document(page_content='Overall, autoencoders are a powerful tool for unsupervised learning. They can be used to find', metadata={}),\n",
       " Document(page_content='patterns in data', metadata={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autoencoders are a type of artificial neural network that are used for unsupervised learning. They'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"ada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.032265063375234604,\n",
       " -0.008701508864760399,\n",
       " 0.007622918579727411,\n",
       " -0.007364850956946611,\n",
       " 0.004724621307104826,\n",
       " 0.014253269881010056,\n",
       " 0.016026657074689865,\n",
       " -0.023993665352463722,\n",
       " 0.0067494590766727924,\n",
       " -0.03581183776259422,\n",
       " 0.008694891817867756,\n",
       " 0.033456142991781235,\n",
       " -0.006028193514794111,\n",
       " -0.022114405408501625,\n",
       " -0.0019123468082398176,\n",
       " 0.012010066770017147,\n",
       " -0.005124956835061312,\n",
       " 0.022604070603847504,\n",
       " 0.0021819942630827427,\n",
       " -0.008450058288872242,\n",
       " -0.03668529540300369,\n",
       " 0.026044972240924835,\n",
       " -0.027394864708185196,\n",
       " -0.04417587071657181,\n",
       " -0.011421144008636475,\n",
       " 0.004082761239260435,\n",
       " 0.014081224799156189,\n",
       " -0.03467369079589844,\n",
       " -0.013591557741165161,\n",
       " -0.00798686034977436,\n",
       " 0.012585756368935108,\n",
       " -0.02270994521677494,\n",
       " -0.007788346614688635,\n",
       " -0.03581183776259422,\n",
       " -0.028294792398810387,\n",
       " -0.013293787837028503,\n",
       " -0.0009139892645180225,\n",
       " -0.025621475651860237,\n",
       " 0.0249068271368742,\n",
       " 0.010289616882801056,\n",
       " 0.019851351156830788,\n",
       " 0.014200332574546337,\n",
       " 0.008966193534433842,\n",
       " -0.024152476340532303,\n",
       " 0.0011100213741883636,\n",
       " -0.005492207128554583,\n",
       " -0.02848007157444954,\n",
       " -0.013194531202316284,\n",
       " -0.003298632800579071,\n",
       " 0.02345106191933155,\n",
       " 0.027421332895755768,\n",
       " 0.02026161178946495,\n",
       " -0.016278106719255447,\n",
       " -0.000896619341801852,\n",
       " -0.025846458971500397,\n",
       " 0.009998464025557041,\n",
       " -0.027183115482330322,\n",
       " 0.011957130394876003,\n",
       " 0.021346818655729294,\n",
       " -0.035097189247608185,\n",
       " -0.0021985371131449938,\n",
       " -0.0341443233191967,\n",
       " -0.02922118827700615,\n",
       " 0.004420233890414238,\n",
       " 0.024748018011450768,\n",
       " -0.011976981535553932,\n",
       " 0.01356508955359459,\n",
       " 0.004767632577568293,\n",
       " 0.01279088668525219,\n",
       " -0.005263916682451963,\n",
       " 0.005257299169898033,\n",
       " 0.012823972851037979,\n",
       " -0.01842205412685871,\n",
       " 0.005968639627099037,\n",
       " 0.014041521586477757,\n",
       " -0.02834772877395153,\n",
       " 0.010282999835908413,\n",
       " -0.030782828107476234,\n",
       " -0.02270994521677494,\n",
       " -0.002003332134336233,\n",
       " 0.02216734178364277,\n",
       " -0.015589927323162556,\n",
       " -0.01720450446009636,\n",
       " -0.00046361173735931516,\n",
       " 0.014769405126571655,\n",
       " 0.012036535888910294,\n",
       " -0.005971948150545359,\n",
       " 0.009733779355883598,\n",
       " -0.0016906734090298414,\n",
       " 0.0019834807608276606,\n",
       " 0.014147396199405193,\n",
       " 0.008933107368648052,\n",
       " 0.000396406656363979,\n",
       " -0.024523034691810608,\n",
       " -0.004450011067092419,\n",
       " 0.018474990501999855,\n",
       " 0.01498115248978138,\n",
       " 0.017283909022808075,\n",
       " 0.0006368975155055523,\n",
       " -0.011864490807056427,\n",
       " -0.007993477396667004,\n",
       " 0.02322608046233654,\n",
       " -0.002074466086924076,\n",
       " -0.018792612478137016,\n",
       " -0.018766144290566444,\n",
       " 0.012367391027510166,\n",
       " 0.0076493872329592705,\n",
       " 0.007298680022358894,\n",
       " 0.01846175640821457,\n",
       " 0.014147396199405193,\n",
       " -0.006392134819179773,\n",
       " 0.049919530749320984,\n",
       " 0.005422727204859257,\n",
       " -0.037638161331415176,\n",
       " 0.009740396402776241,\n",
       " -0.011765234172344208,\n",
       " 0.0076427701860666275,\n",
       " 0.0058230627328157425,\n",
       " -0.0013283862499520183,\n",
       " -0.0053234705701470375,\n",
       " 0.01093809399753809,\n",
       " 0.023279016837477684,\n",
       " 0.02760661207139492,\n",
       " -0.008886788040399551,\n",
       " 0.002531047211959958,\n",
       " 0.014041521586477757,\n",
       " 0.014610594138503075,\n",
       " -0.009647756814956665,\n",
       " -0.029115313664078712,\n",
       " -0.009707310236990452,\n",
       " -0.008112585172057152,\n",
       " 0.0026551182381808758,\n",
       " 0.012896760366857052,\n",
       " 0.03459428623318672,\n",
       " -0.015934016555547714,\n",
       " 0.02609790861606598,\n",
       " 0.018858782947063446,\n",
       " -0.004383840132504702,\n",
       " -0.019401386380195618,\n",
       " -0.013909179717302322,\n",
       " 0.0030091339722275734,\n",
       " 0.02077774703502655,\n",
       " -0.018223538994789124,\n",
       " -0.00886031985282898,\n",
       " -0.015232603065669537,\n",
       " 0.00404305849224329,\n",
       " -0.0032705101184546947,\n",
       " 0.0407085046172142,\n",
       " -0.00834418460726738,\n",
       " -0.0006513724219985306,\n",
       " -0.006200238596647978,\n",
       " -0.034779567271471024,\n",
       " -0.01823677495121956,\n",
       " -0.005852839909493923,\n",
       " 0.023279016837477684,\n",
       " 0.02493329718708992,\n",
       " 0.020526297390460968,\n",
       " -0.005912393797188997,\n",
       " -0.010223445482552052,\n",
       " 0.0038842475041747093,\n",
       " -0.014213566668331623,\n",
       " 0.005187819711863995,\n",
       " -0.021267414093017578,\n",
       " -0.01794562116265297,\n",
       " 0.030941639095544815,\n",
       " 0.01981164701282978,\n",
       " -0.0113748237490654,\n",
       " 0.00998522900044918,\n",
       " -0.012168877758085728,\n",
       " -0.011745382100343704,\n",
       " -0.004549267701804638,\n",
       " 0.00419525196775794,\n",
       " -0.011553485877811909,\n",
       " 0.012817355804145336,\n",
       " 0.015020855702459812,\n",
       " 0.016833946108818054,\n",
       " 0.016476621851325035,\n",
       " 0.011163076385855675,\n",
       " -0.045763980597257614,\n",
       " -0.013750368729233742,\n",
       " 0.01183802168816328,\n",
       " 0.015351710841059685,\n",
       " 0.014928216114640236,\n",
       " 0.02486712485551834,\n",
       " -0.011751999147236347,\n",
       " -0.006633659824728966,\n",
       " 0.025343557819724083,\n",
       " 0.002028146293014288,\n",
       " 0.007172954734414816,\n",
       " -0.012036535888910294,\n",
       " 0.001412754412740469,\n",
       " 0.008628720417618752,\n",
       " 0.009177940897643566,\n",
       " -0.0013358304277062416,\n",
       " -0.6288908123970032,\n",
       " -0.01565609872341156,\n",
       " 0.025925863534212112,\n",
       " -0.01294969767332077,\n",
       " 0.0008213496184907854,\n",
       " 0.026971368119120598,\n",
       " -0.0143062062561512,\n",
       " -0.0052076708525419235,\n",
       " -0.02091008983552456,\n",
       " 0.012989399954676628,\n",
       " 0.01578844152390957,\n",
       " 0.00756998173892498,\n",
       " -0.024245116859674454,\n",
       " 0.014584125950932503,\n",
       " 0.015603161416947842,\n",
       " -0.0249068271368742,\n",
       " -0.007622918579727411,\n",
       " -0.030174052342772484,\n",
       " 0.020579233765602112,\n",
       " -0.0033333725295960903,\n",
       " -0.019732242450118065,\n",
       " 0.01601342298090458,\n",
       " -0.009846270084381104,\n",
       " 0.006828864570707083,\n",
       " 0.0019652836490422487,\n",
       " 0.017826512455940247,\n",
       " 0.012896760366857052,\n",
       " 0.00864857155829668,\n",
       " 0.011652742512524128,\n",
       " -0.009078684262931347,\n",
       " -0.03877630457282066,\n",
       " 0.03496484458446503,\n",
       " 0.009442625567317009,\n",
       " 0.002132365945726633,\n",
       " 0.032423872500658035,\n",
       " 0.004254806321114302,\n",
       " -0.006954589858651161,\n",
       " 0.021412990987300873,\n",
       " 0.01565609872341156,\n",
       " 0.04081437736749649,\n",
       " -0.02255113422870636,\n",
       " -0.04544635862112045,\n",
       " -0.0029677769634872675,\n",
       " -0.01758829690515995,\n",
       " 0.0027676091995090246,\n",
       " 0.0022415483836084604,\n",
       " -0.02893003448843956,\n",
       " -0.0003234116011299193,\n",
       " 0.007794963661581278,\n",
       " -0.014345909468829632,\n",
       " -0.006928121205419302,\n",
       " -0.019348450005054474,\n",
       " -0.012651927769184113,\n",
       " -0.012089472264051437,\n",
       " 0.004238263238221407,\n",
       " 0.0010182088008150458,\n",
       " 0.018567629158496857,\n",
       " 0.0043970742262899876,\n",
       " 0.034064918756484985,\n",
       " -0.0017800044734030962,\n",
       " 0.03668529540300369,\n",
       " 0.01603989116847515,\n",
       " -0.028374196961522102,\n",
       " -0.0095220310613513,\n",
       " -0.002699783770367503,\n",
       " 0.011500549502670765,\n",
       " -0.009078684262931347,\n",
       " 0.00609767297282815,\n",
       " -0.014226801693439484,\n",
       " -0.03472663089632988,\n",
       " 0.032000377774238586,\n",
       " 0.014795873314142227,\n",
       " 0.003960344474762678,\n",
       " 0.007186188828200102,\n",
       " -0.0007254014490172267,\n",
       " 0.02322608046233654,\n",
       " 0.010865305550396442,\n",
       " -0.01823677495121956,\n",
       " -0.008575783111155033,\n",
       " -0.013273936696350574,\n",
       " 0.02264377474784851,\n",
       " -0.005806520115584135,\n",
       " -0.032000377774238586,\n",
       " -0.01277103554457426,\n",
       " 0.01949402689933777,\n",
       " -0.0023590021301060915,\n",
       " -0.011189544573426247,\n",
       " -0.01410769298672676,\n",
       " -0.022723179310560226,\n",
       " 0.0013019177131354809,\n",
       " 0.019017593935132027,\n",
       " 0.018408820033073425,\n",
       " 0.007477342151105404,\n",
       " -0.02980349399149418,\n",
       " -0.021823251619935036,\n",
       " 0.022590836510062218,\n",
       " -0.023279016837477684,\n",
       " -0.012109323404729366,\n",
       " 0.01920287311077118,\n",
       " -0.039517421275377274,\n",
       " 0.011996832676231861,\n",
       " -0.0045194909907877445,\n",
       " 0.01871320605278015,\n",
       " 0.014041521586477757,\n",
       " -0.018289711326360703,\n",
       " 0.00756998173892498,\n",
       " 0.006782544776797295,\n",
       " 0.004320977255702019,\n",
       " 0.029724089428782463,\n",
       " -0.015259071253240108,\n",
       " 0.0007828876259736717,\n",
       " 0.0059388624504208565,\n",
       " 0.017164800316095352,\n",
       " -6.119540557847358e-06,\n",
       " -0.01565609872341156,\n",
       " -0.03919979929924011,\n",
       " 0.0008949650800786912,\n",
       " 0.019096998497843742,\n",
       " 0.018924953415989876,\n",
       " -0.038485150784254074,\n",
       " 0.030809296295046806,\n",
       " 0.004588970448821783,\n",
       " -0.018064729869365692,\n",
       " 0.0003351983323227614,\n",
       " 0.00584622286260128,\n",
       " 0.012215198017656803,\n",
       " -0.004241571761667728,\n",
       " -0.025184746831655502,\n",
       " -0.02951234206557274,\n",
       " -0.008562549017369747,\n",
       " 0.005154734011739492,\n",
       " 0.004966146312654018,\n",
       " -0.021121837198734283,\n",
       " -0.0018610641127452254,\n",
       " 0.043990593403577805,\n",
       " 0.014928216114640236,\n",
       " 0.04523460939526558,\n",
       " 0.0044103083200752735,\n",
       " 0.008516229689121246,\n",
       " 0.004000047221779823,\n",
       " -0.007245743181556463,\n",
       " -0.014134161174297333,\n",
       " 0.014226801693439484,\n",
       " 0.011573337018489838,\n",
       " -0.019851351156830788,\n",
       " -0.014438549056649208,\n",
       " 0.003745288122445345,\n",
       " -0.014226801693439484,\n",
       " 0.0020165664609521627,\n",
       " 0.027818359434604645,\n",
       " -0.005971948150545359,\n",
       " -0.0005368136335164309,\n",
       " -0.01785298064351082,\n",
       " 0.007967008277773857,\n",
       " 0.022087935358285904,\n",
       " -0.02805657498538494,\n",
       " -0.007292062975466251,\n",
       " -0.020142503082752228,\n",
       " -0.022723179310560226,\n",
       " -0.038511618971824646,\n",
       " -0.011963747441768646,\n",
       " 0.022736413404345512,\n",
       " -0.0009710618760436773,\n",
       " 0.022855522111058235,\n",
       " -0.0070406123995780945,\n",
       " -0.016225170344114304,\n",
       " -0.0037022768519818783,\n",
       " 0.03041226975619793,\n",
       " -0.021545331925153732,\n",
       " -0.012976165860891342,\n",
       " 0.0019024211214855313,\n",
       " -0.03297971189022064,\n",
       " -0.023848088458180428,\n",
       " 0.0438053123652935,\n",
       " -0.00756998173892498,\n",
       " 0.007636152673512697,\n",
       " -0.007900837808847427,\n",
       " -0.00548559008166194,\n",
       " 0.015470819547772408,\n",
       " 0.0019768637139350176,\n",
       " 0.0005632820539176464,\n",
       " -0.005740348715335131,\n",
       " -0.0166486669331789,\n",
       " -0.01574873737990856,\n",
       " 0.007940540090203285,\n",
       " 0.004413616843521595,\n",
       " 0.02668021433055401,\n",
       " 0.015841377899050713,\n",
       " -0.012254900299012661,\n",
       " 0.0020314548164606094,\n",
       " -0.015709035098552704,\n",
       " 0.033456142991781235,\n",
       " 0.0005603870959021151,\n",
       " 0.02136005274951458,\n",
       " 0.017191270366311073,\n",
       " 0.018183836713433266,\n",
       " 0.019176404923200607,\n",
       " -0.00509848864749074,\n",
       " -0.002595564117655158,\n",
       " 0.011500549502670765,\n",
       " 0.002367273671552539,\n",
       " -0.018501458689570427,\n",
       " 0.03885570913553238,\n",
       " 0.014279738068580627,\n",
       " 0.03231799975037575,\n",
       " -0.026018504053354263,\n",
       " 0.005548452492803335,\n",
       " -0.0020959717221558094,\n",
       " 0.020698342472314835,\n",
       " -0.004486405290663242,\n",
       " 0.005416110157966614,\n",
       " -0.02760661207139492,\n",
       " -0.009694076143205166,\n",
       " -0.015907548367977142,\n",
       " 0.0008635337580926716,\n",
       " 0.04766970872879028,\n",
       " -0.0036691913846880198,\n",
       " 0.037161726504564285,\n",
       " -0.01386947650462389,\n",
       " -0.021214475855231285,\n",
       " -0.014531188644468784,\n",
       " -0.013333490118384361,\n",
       " 0.017350081354379654,\n",
       " 0.009442625567317009,\n",
       " 0.004982688929885626,\n",
       " 0.02093655802309513,\n",
       " -0.002612106967717409,\n",
       " 0.012585756368935108,\n",
       " -0.00484042102470994,\n",
       " -0.039252735674381256,\n",
       " 0.0003595989546738565,\n",
       " 0.022021764889359474,\n",
       " 0.007179571781307459,\n",
       " 0.012036535888910294,\n",
       " 0.02113507129251957,\n",
       " 0.007556747645139694,\n",
       " 0.016026657074689865,\n",
       " -0.010488130152225494,\n",
       " 0.02151886373758316,\n",
       " -0.01572226919233799,\n",
       " -0.017085395753383636,\n",
       " 0.01819707080721855,\n",
       " 0.0004702288715634495,\n",
       " -0.0030157510191202164,\n",
       " 0.02657434158027172,\n",
       " 0.007867751643061638,\n",
       " 0.04142315313220024,\n",
       " 0.006206855643540621,\n",
       " -0.03337673842906952,\n",
       " 0.02364957518875599,\n",
       " -0.028162449598312378,\n",
       " 0.014689999632537365,\n",
       " 0.01513996347784996,\n",
       " 0.01864703558385372,\n",
       " -8.436824282398447e-05,\n",
       " -0.006679979618638754,\n",
       " 0.013975351117551327,\n",
       " 0.0010612200712785125,\n",
       " 0.0407085046172142,\n",
       " 0.03366789221763611,\n",
       " 0.0021439457777887583,\n",
       " -0.00034884613705798984,\n",
       " -0.009806566871702671,\n",
       " 0.002122440142557025,\n",
       " 0.0009503834298811853,\n",
       " -0.012228432111442089,\n",
       " 0.02818891778588295,\n",
       " -0.01243356242775917,\n",
       " -0.0025277386885136366,\n",
       " 0.008555931970477104,\n",
       " -0.015166431665420532,\n",
       " -0.012559288181364536,\n",
       " -0.012751184403896332,\n",
       " -0.015166431665420532,\n",
       " 0.03636767342686653,\n",
       " 0.005707263480871916,\n",
       " 0.007543513085693121,\n",
       " 0.016410449519753456,\n",
       " 0.0341443233191967,\n",
       " 0.028585944324731827,\n",
       " -0.022273214533925056,\n",
       " -0.031682755798101425,\n",
       " 0.03425019606947899,\n",
       " 0.026666980236768723,\n",
       " 0.004086069762706757,\n",
       " -0.03557362034916878,\n",
       " -0.043275944888591766,\n",
       " 0.012552671134471893,\n",
       " -0.016053125262260437,\n",
       " -0.009277197532355785,\n",
       " 0.003927258774638176,\n",
       " 0.026309655979275703,\n",
       " -0.011467463336884975,\n",
       " 0.007530278991907835,\n",
       " -0.018501458689570427,\n",
       " 0.011778468266129494,\n",
       " 0.0391203947365284,\n",
       " 0.007662621326744556,\n",
       " 0.0016551063163205981,\n",
       " -0.020963026210665703,\n",
       " -0.022604070603847504,\n",
       " 0.027712484821677208,\n",
       " 0.008019945584237576,\n",
       " -0.026177315041422844,\n",
       " 0.03266208991408348,\n",
       " -0.004724621307104826,\n",
       " -0.007450873497873545,\n",
       " 4.939574500895105e-05,\n",
       " 0.00466175889596343,\n",
       " -0.019917521625757217,\n",
       " -0.009197792038321495,\n",
       " 0.025237683206796646,\n",
       " 0.010607237927615643,\n",
       " 0.012810737825930119,\n",
       " -0.006507934536784887,\n",
       " -0.001482234220020473,\n",
       " -0.021796783432364464,\n",
       " -0.008158905431628227,\n",
       " 0.01157995406538248,\n",
       " 0.0277654230594635,\n",
       " 0.006253175437450409,\n",
       " -0.024721547961235046,\n",
       " -0.009694076143205166,\n",
       " 0.01987781934440136,\n",
       " 0.01794562116265297,\n",
       " 0.01364449504762888,\n",
       " -0.014769405126571655,\n",
       " -0.0014069644967094064,\n",
       " -0.026269953697919846,\n",
       " 0.021240945905447006,\n",
       " -0.03133866563439369,\n",
       " -0.020155737176537514,\n",
       " -0.018819080665707588,\n",
       " 0.0006637795595452189,\n",
       " -0.024827422574162483,\n",
       " 0.0068023959174752235,\n",
       " 0.012698247097432613,\n",
       " -0.012162260711193085,\n",
       " 0.005280459299683571,\n",
       " 0.019957223907113075,\n",
       " -0.008635337464511395,\n",
       " -0.029406467452645302,\n",
       " -0.024178944528102875,\n",
       " -0.030650485306978226,\n",
       " 0.0028106204699724913,\n",
       " -0.003311866894364357,\n",
       " 0.00850299559533596,\n",
       " 0.004443394020199776,\n",
       " 0.02677285484969616,\n",
       " -0.006987675558775663,\n",
       " 0.004886740818619728,\n",
       " 0.029115313664078712,\n",
       " -0.007616301532834768,\n",
       " -0.03115338645875454,\n",
       " -0.008317715488374233,\n",
       " 0.0407085046172142,\n",
       " 0.006203547120094299,\n",
       " 0.018699971958994865,\n",
       " -0.01682071015238762,\n",
       " 0.0318945050239563,\n",
       " 0.012552671134471893,\n",
       " 0.03739994391798973,\n",
       " 0.012340922839939594,\n",
       " 0.0012721407692879438,\n",
       " 0.011388057842850685,\n",
       " 0.024046603590250015,\n",
       " 0.017389783635735512,\n",
       " -0.019321981817483902,\n",
       " -0.008880170993506908,\n",
       " -0.019639603793621063,\n",
       " 0.03149747475981712,\n",
       " 0.0016890190308913589,\n",
       " 0.002092663198709488,\n",
       " -0.01911023259162903,\n",
       " 0.015113495290279388,\n",
       " 0.006739533506333828,\n",
       " -0.027368394657969475,\n",
       " 0.019255809485912323,\n",
       " -0.013227616436779499,\n",
       " -0.028691818937659264,\n",
       " 0.020314548164606094,\n",
       " 0.009349985979497433,\n",
       " -0.004334211349487305,\n",
       " 0.007192805875092745,\n",
       " -0.0014028287259861827,\n",
       " -0.02502593584358692,\n",
       " 0.011957130394876003,\n",
       " -0.013750368729233742,\n",
       " 0.019917521625757217,\n",
       " 0.004459936637431383,\n",
       " 0.021240945905447006,\n",
       " -0.00850299559533596,\n",
       " -0.014822341501712799,\n",
       " -0.012751184403896332,\n",
       " 0.002173722954466939,\n",
       " -0.03631473705172539,\n",
       " -0.02699783630669117,\n",
       " 0.006640276871621609,\n",
       " -0.004688227083534002,\n",
       " 0.03570596128702164,\n",
       " 0.023345189169049263,\n",
       " -0.020274845883250237,\n",
       " -0.005578229669481516,\n",
       " 0.04134374484419823,\n",
       " 0.005244065076112747,\n",
       " -0.006795778870582581,\n",
       " -0.006663436535745859,\n",
       " -0.03157688304781914,\n",
       " -0.022405557334423065,\n",
       " 0.003957035951316357,\n",
       " -0.022114405408501625,\n",
       " -0.021730611100792885,\n",
       " -0.0003494664852041751,\n",
       " -0.02225998044013977,\n",
       " 0.026336126029491425,\n",
       " -0.026944899931550026,\n",
       " 0.02519798092544079,\n",
       " 0.010865305550396442,\n",
       " 0.01091824285686016,\n",
       " 0.025343557819724083,\n",
       " 0.012479882687330246,\n",
       " 0.0056146238930523396,\n",
       " 0.02151886373758316,\n",
       " -0.043699439615011215,\n",
       " 0.003791607916355133,\n",
       " -0.006895035970956087,\n",
       " -0.013532004319131374,\n",
       " -0.006795778870582581,\n",
       " 0.014041521586477757,\n",
       " -0.0030951565131545067,\n",
       " 0.0027626461815088987,\n",
       " 0.007788346614688635,\n",
       " -0.005581538192927837,\n",
       " -0.01619870215654373,\n",
       " 0.018991125747561455,\n",
       " 0.024734782055020332,\n",
       " -0.008635337464511395,\n",
       " -0.0020000236108899117,\n",
       " 0.00558815523982048,\n",
       " 0.002051306189969182,\n",
       " -0.0042349547147750854,\n",
       " -0.023914260789752007,\n",
       " -0.00466175889596343,\n",
       " -0.01364449504762888,\n",
       " -0.0037585224490612745,\n",
       " -0.01772063970565796,\n",
       " 0.019308747723698616,\n",
       " 0.002764300676062703,\n",
       " -0.025343557819724083,\n",
       " 0.00545912142843008,\n",
       " 0.0047213127836585045,\n",
       " -0.005720497574657202,\n",
       " -0.004704770166426897,\n",
       " 0.008575783111155033,\n",
       " -0.014412080869078636,\n",
       " 0.044890519231557846,\n",
       " -0.011765234172344208,\n",
       " -0.039676234126091,\n",
       " -0.009204410016536713,\n",
       " -0.005601389333605766,\n",
       " -0.011308652348816395,\n",
       " 0.004129081033170223,\n",
       " -0.0007303642923943698,\n",
       " -0.017257440835237503,\n",
       " -0.01145422924309969,\n",
       " 0.032291531562805176,\n",
       " -0.002883408684283495,\n",
       " -0.03697644919157028,\n",
       " 0.003076959401369095,\n",
       " -0.03679116815328598,\n",
       " -0.03054461069405079,\n",
       " 0.024337755516171455,\n",
       " 0.01227475143969059,\n",
       " 0.035388339310884476,\n",
       " -0.029565278440713882,\n",
       " 0.03160335123538971,\n",
       " 0.00550874974578619,\n",
       " -0.04571104422211647,\n",
       " 0.01438561175018549,\n",
       " -0.029618214815855026,\n",
       " -0.004483096767216921,\n",
       " 0.0001752501993905753,\n",
       " 0.02106890082359314,\n",
       " 0.006335889454931021,\n",
       " 0.029353531077504158,\n",
       " 0.0058164456859230995,\n",
       " 0.018501458689570427,\n",
       " 0.005955405067652464,\n",
       " 0.005981873720884323,\n",
       " 0.005545143969357014,\n",
       " 0.022339386865496635,\n",
       " -0.0011670939857140183,\n",
       " -0.028533007949590683,\n",
       " 0.013293787837028503,\n",
       " 0.020182207226753235,\n",
       " -0.009184557944536209,\n",
       " 0.022948160767555237,\n",
       " -0.004876815248280764,\n",
       " 0.020632170140743256,\n",
       " 0.025687647983431816,\n",
       " 0.006273026578128338,\n",
       " -0.025502368807792664,\n",
       " 0.007622918579727411,\n",
       " -0.023318719118833542,\n",
       " -0.009978611953556538,\n",
       " 0.022895224392414093,\n",
       " 0.016291340813040733,\n",
       " 0.0087478281930089,\n",
       " -0.02589939534664154,\n",
       " 0.0052010538056492805,\n",
       " 0.021399755030870438,\n",
       " 0.008172139525413513,\n",
       " 0.023503998294472694,\n",
       " 0.005551761016249657,\n",
       " 0.04020560160279274,\n",
       " 0.006187004502862692,\n",
       " -0.0018362499540671706,\n",
       " -0.0005938862450420856,\n",
       " -0.007397936657071114,\n",
       " -0.01093809399753809,\n",
       " 0.0053300876170396805,\n",
       " -0.04351416230201721,\n",
       " -0.011282184161245823,\n",
       " 0.03758522495627403,\n",
       " 0.024430396035313606,\n",
       " 0.011268950067460537,\n",
       " 0.015854611992836,\n",
       " -0.005631166510283947,\n",
       " 0.004804026801139116,\n",
       " -0.001186945359222591,\n",
       " -0.015854611992836,\n",
       " -0.006610499694943428,\n",
       " -0.033164989203214645,\n",
       " -0.02380838617682457,\n",
       " 0.0003500868333503604,\n",
       " -0.05357217788696289,\n",
       " -0.017389783635735512,\n",
       " -0.013816540129482746,\n",
       " 0.003065379336476326,\n",
       " 0.026494935154914856,\n",
       " -0.010269765742123127,\n",
       " 0.032106250524520874,\n",
       " -0.020857151597738266,\n",
       " -0.01938815228641033,\n",
       " 0.028691818937659264,\n",
       " 0.02670668438076973,\n",
       " 0.026203783228993416,\n",
       " -0.0019057296449318528,\n",
       " 0.026971368119120598,\n",
       " 0.03869690001010895,\n",
       " -0.010752814821898937,\n",
       " -0.021188007667660713,\n",
       " 0.01574873737990856,\n",
       " 0.009535265155136585,\n",
       " -0.001973555190488696,\n",
       " 0.014081224799156189,\n",
       " 0.0203542523086071,\n",
       " -0.005217596422880888,\n",
       " -0.014517954550683498,\n",
       " 0.01394888199865818,\n",
       " -0.014954684302210808,\n",
       " 0.0002388365683145821,\n",
       " -0.039093926548957825,\n",
       " 0.006686596665531397,\n",
       " -0.0024516417179256678,\n",
       " 0.0066138082183897495,\n",
       " 0.002531047211959958,\n",
       " -0.02416571043431759,\n",
       " 0.01042195875197649,\n",
       " 0.003235770156607032,\n",
       " -0.017958855256438255,\n",
       " 0.010673409327864647,\n",
       " -0.02113507129251957,\n",
       " -0.006001724861562252,\n",
       " -0.03072988986968994,\n",
       " 0.037744034081697464,\n",
       " -0.019441088661551476,\n",
       " 0.009978611953556538,\n",
       " 0.002823854563757777,\n",
       " -0.0003728331648744643,\n",
       " 0.0007770976517349482,\n",
       " 0.005002540536224842,\n",
       " -0.007431022357195616,\n",
       " 0.004923135042190552,\n",
       " 0.007841283455491066,\n",
       " 0.02084391750395298,\n",
       " 0.02264377474784851,\n",
       " 0.008734594099223614,\n",
       " 0.019983692094683647,\n",
       " 0.014729701913893223,\n",
       " -0.017244206741452217,\n",
       " -0.004205177538096905,\n",
       " -0.010249913670122623,\n",
       " 0.02803010679781437,\n",
       " -0.028691818937659264,\n",
       " -0.010216828435659409,\n",
       " 0.005230830982327461,\n",
       " 0.000553356425371021,\n",
       " -0.0019123468082398176,\n",
       " 0.0036063287407159805,\n",
       " -0.0028470144607126713,\n",
       " -0.018858782947063446,\n",
       " -0.03520306199789047,\n",
       " -0.025171512737870216,\n",
       " 0.03305911645293236,\n",
       " 9.145062358584255e-05,\n",
       " -0.016291340813040733,\n",
       " 0.000659230281598866,\n",
       " -0.017839746549725533,\n",
       " 0.005376407410949469,\n",
       " -0.011143225245177746,\n",
       " -0.009694076143205166,\n",
       " 0.040258537977933884,\n",
       " -0.04939015954732895,\n",
       " 0.005482281558215618,\n",
       " -0.004764324054121971,\n",
       " 0.00790745485574007,\n",
       " 0.035970646888017654,\n",
       " 0.012678395956754684,\n",
       " -0.013201148249208927,\n",
       " -0.002936345525085926,\n",
       " 0.04068203270435333,\n",
       " -0.0045194909907877445,\n",
       " 0.02628318779170513,\n",
       " 0.01727067492902279,\n",
       " 0.011143225245177746,\n",
       " -0.007781729567795992,\n",
       " 0.013790071941912174,\n",
       " -0.004162166733294725,\n",
       " -0.012473265640437603,\n",
       " 0.003047182224690914,\n",
       " -0.037320539355278015,\n",
       " -0.016278106719255447,\n",
       " -0.014398845843970776,\n",
       " -0.008529463782906532,\n",
       " 0.009892589412629604,\n",
       " 0.009958760812878609,\n",
       " 0.0028205460403114557,\n",
       " -0.011156459338963032,\n",
       " 0.015642864629626274,\n",
       " 0.005287076346576214,\n",
       " -0.005780051462352276,\n",
       " -0.024787720292806625,\n",
       " 0.017548594623804092,\n",
       " 0.007093549240380526,\n",
       " -0.0012067967327311635,\n",
       " 0.0038346191868185997,\n",
       " -0.026984602212905884,\n",
       " -0.024006899446249008,\n",
       " 0.006921504158526659,\n",
       " 0.019176404923200607,\n",
       " -0.006335889454931021,\n",
       " -0.01790591888129711,\n",
       " -0.011619657278060913,\n",
       " -0.022021764889359474,\n",
       " 0.01772063970565796,\n",
       " -0.001887532533146441,\n",
       " 0.002555861370638013,\n",
       " 0.002526084426790476,\n",
       " -0.0031911046244204044,\n",
       " -0.013300404883921146,\n",
       " 0.003986813127994537,\n",
       " 0.011527017690241337,\n",
       " -0.041476089507341385,\n",
       " 0.007801580708473921,\n",
       " 0.006534402724355459,\n",
       " 0.01588108018040657,\n",
       " 0.001523591112345457,\n",
       " -0.03800871968269348,\n",
       " -0.017098629847168922,\n",
       " -0.0023540393449366093,\n",
       " -0.001693981932476163,\n",
       " -0.01610606163740158,\n",
       " 0.010772665962576866,\n",
       " -0.01785298064351082,\n",
       " 0.033456142991781235,\n",
       " -0.015166431665420532,\n",
       " -0.026786088943481445,\n",
       " -2.2242300474317744e-05,\n",
       " -0.007199422921985388,\n",
       " -0.024761252105236053,\n",
       " -4.732789602712728e-05,\n",
       " -0.0362088643014431,\n",
       " 0.0076427701860666275,\n",
       " 0.007483959197998047,\n",
       " 0.031365133821964264,\n",
       " -0.013856242410838604,\n",
       " 0.01050136424601078,\n",
       " 0.004142315126955509,\n",
       " 0.019864585250616074,\n",
       " -0.009654373861849308,\n",
       " 0.00047560528037138283,\n",
       " -0.0087478281930089,\n",
       " 0.011302035301923752,\n",
       " -0.016860414296388626,\n",
       " -0.004459936637431383,\n",
       " -0.03753228858113289,\n",
       " 0.006861950270831585,\n",
       " 0.010818986222147942,\n",
       " -0.030332863330841064,\n",
       " 0.0023341879714280367,\n",
       " 0.020248377695679665,\n",
       " -0.018091198056936264,\n",
       " -0.011149842292070389,\n",
       " -0.001465691369958222,\n",
       " 0.01675453968346119,\n",
       " 0.027011070400476456,\n",
       " -0.01238724309951067,\n",
       " 0.04968131333589554,\n",
       " -0.015192900784313679,\n",
       " -0.016436917707324028,\n",
       " -0.008959576487541199,\n",
       " -0.012294603511691093,\n",
       " -0.01826324313879013,\n",
       " -0.012122558429837227,\n",
       " 0.018660269677639008,\n",
       " 0.01936168409883976,\n",
       " -0.001438395818695426,\n",
       " -0.02677285484969616,\n",
       " -0.0005161351291462779,\n",
       " 0.00352692324668169,\n",
       " 0.0025095415767282248,\n",
       " 0.032715026289224625,\n",
       " 0.024628909304738045,\n",
       " -0.004258114844560623,\n",
       " 0.034488413482904434,\n",
       " 0.012314454652369022,\n",
       " -0.0051414999179542065,\n",
       " -0.010607237927615643,\n",
       " -0.00831109844148159,\n",
       " -0.008383886888623238,\n",
       " 0.02116153948009014,\n",
       " 0.011593189090490341,\n",
       " -0.0020231835078448057,\n",
       " -0.0127114811912179,\n",
       " -0.0007952947053126991,\n",
       " 0.02713017910718918,\n",
       " -0.017085395753383636,\n",
       " -0.004995923023670912,\n",
       " 0.008317715488374233,\n",
       " 0.015563459135591984,\n",
       " -0.01626487262547016,\n",
       " 0.03245034068822861,\n",
       " -0.025780286639928818,\n",
       " -0.0030852307099848986,\n",
       " 0.01581490971148014,\n",
       " -0.002155525842681527,\n",
       " -0.01848822459578514,\n",
       " 0.0005264743813313544,\n",
       " -0.009819801896810532,\n",
       " 0.006286261137574911,\n",
       " -0.02161150425672531,\n",
       " 0.018792612478137016,\n",
       " -0.005237448029220104,\n",
       " -0.027011070400476456,\n",
       " -0.027394864708185196,\n",
       " 0.013214382342994213,\n",
       " -0.00787436868995428,\n",
       " -0.018991125747561455,\n",
       " 0.00872797705233097,\n",
       " 0.19311393797397614,\n",
       " -0.011474080383777618,\n",
       " 0.005988490767776966,\n",
       " 0.019057296216487885,\n",
       " -0.008026562631130219,\n",
       " -0.00012386415619403124,\n",
       " 0.023080503568053246,\n",
       " -0.005297001916915178,\n",
       " -0.01380330603569746,\n",
       " 0.010666792280972004,\n",
       " -0.015126729384064674,\n",
       " 0.017283909022808075,\n",
       " -0.029724089428782463,\n",
       " 0.0025277386885136366,\n",
       " 0.012744567357003689,\n",
       " -0.011024116538465023,\n",
       " -0.030676953494548798,\n",
       " -0.010329319164156914,\n",
       " -0.00824492797255516,\n",
       " 0.006570796947926283,\n",
       " -0.006190313026309013,\n",
       " 0.0015847994945943356,\n",
       " -0.019242575392127037,\n",
       " -0.034064918756484985,\n",
       " 0.030518142506480217,\n",
       " -0.009224261157214642,\n",
       " -0.013326873071491718,\n",
       " 0.012764418497681618,\n",
       " 0.029882900416851044,\n",
       " 0.021267414093017578,\n",
       " -0.028400665149092674,\n",
       " 0.004913209471851587,\n",
       " 0.011831404641270638,\n",
       " 0.007318531163036823,\n",
       " -0.013551855459809303,\n",
       " 0.0017882757820189,\n",
       " 0.014187098480761051,\n",
       " 0.0022001913748681545,\n",
       " 0.018223538994789124,\n",
       " 0.04462583735585213,\n",
       " 0.009052216075360775,\n",
       " -0.010335936211049557,\n",
       " 0.00993890967220068,\n",
       " 0.00018755390192382038,\n",
       " -0.002595564117655158,\n",
       " 0.01997045800089836,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pinecone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-55613560a7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialise Pinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pinecone'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Initialise Pinecone\n",
    "Pinecone.init(api_key=os.getenv(\"PINECONE_API_KEY\"), \n",
    "              environment=os.getenv(\"PINECONE_ENV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
